# EXPOSING-DEEP-FAKE-FACE-DETECTION-USING-CNN-AND-LSTM

### OverView

The rapid advancement of artificial intelligence, particularly in the realm of deep learning, has led to the emergence of deep-fake technology, allowing the creation of hyper-realistic multimedia content that can deceive human perception. The consequences of maliciously deployed deep-fakes range from misinformation and reputation damage to potential threats to national security. As a countermeasure to this escalating challenge, the development of effective deep-fake detection methods has become imperative. This paper introduces a novel approach to deep-fake detection, combining the strengths of Residual Networks and Long Short-Term Memory with Convolutional Neural Networks to create a hybrid architecture that excels in capturing both spatial and temporal features.
The proposed hybrid model aims to address the limitations of existing deep-fake detection techniques by leveraging the comprehensive spatial understanding offered by ResNet and the nuanced temporal dependencies modeled through LSTM-CNN fusion. With the exponential growth in deep-fake sophistication, conventional methods often struggle to discern subtle manipulations in facial features and fail to capture the temporal dynamics inherent in video sequences. In response, our approach not only integrates these two powerful neural network architectures but also employs transfer learning strategies to enhance generalization, enabling the model to adapt effectively to the diverse and evolving landscape of deep-fake creation methods.

### Scope Of Project
The primary purpose of the topic "Exposing Fake Faces Through Deep Neural Networks Combining Content and Trace Feature Extractors" is to address the increasing prevalence of AI-manipulated fake face media, such as DeepFake and Face2Face, and the potential social, ethical, and legal implications associated with their misuse. The research aims to develop a model that can effectively detect and expose fake faces in media, thereby contributing to the preservation of individual privacy and the prevention of the spread of misinformation and fake content. The project also seeks to leverage deep neural networks and advanced image forensics techniques to enhance the accuracy and robustness of fake face detection, ultimately serving the broader goal of maintaining the authenticity and integrity of visual media in the digital age.

### Objectives 

The objective of this project is to create systems that can synthesize video-sequences of expressions and mimics of a particular individual. Training the system to generate deep-fake multimedia using limited datasets i.e., The system is able to initialize the parameters of both the generator and the discriminator in a person-specific way, so that training can be based on just a few images and done quickly, despite the need to tune tens of millions of parameters.
We also propose a face forensics model that mashes up the conventional image forensic approach and the fake face image forensic approach for fake multimedia detection
